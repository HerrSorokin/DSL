{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Job#2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNF302DrwLFWzcb0mLbXCY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HerrSorokin/DSL/blob/main/Job_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sAP3L2nTJS5"
      },
      "source": [
        "To clean our grammar, we find all productive and reachable non-terminals and then take away all needless. \n",
        "\n",
        "First, we find productive non-terminals by looking through every non-terminal and its product rules, noting those NT whose right side of the rule contains only tokens or other productive non-terminals.\n",
        "\n",
        "Second, we find reachable NT. The first reachable NT is main NT, then we add all NT contained in its rules to the set of reachable and repeat this operation with the set of reachable while it grows.\n",
        "\n",
        "Third, we compare the original set of NT with the union of productive and reachable NT and include only productive NT with rules containing just reachable  NT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlen-i1L1PE-"
      },
      "source": [
        "def clean_external(gr):\n",
        "\n",
        "  toks = gr['toks']\n",
        "  vars = gr['vars']\n",
        "  n_extr = set()\n",
        "  \n",
        "  #вспомогательная функция для определения продуктивности нетерминала\n",
        "  def is_non_external(definition):\n",
        "    return any(map(is_rule_right, definition))\n",
        "\n",
        "  #вспомогательная функция для анализа правой части правила на непродуктивные нетерминалы\n",
        "  def is_rule_right(rule):\n",
        "    return all(map((lambda part: part in toks.union(n_extr)), rule))\n",
        "\n",
        "  #вспомогательная функция для \"очищения\" правил от непродуктивныъ нетерминалов\n",
        "  def clean_definition(definition):\n",
        "    new_definition = []\n",
        "    for rule in definition:\n",
        "        if is_rule_right(rule):\n",
        "          new_definition.append(rule)\n",
        "    return new_definition\n",
        "\n",
        "\n",
        "  #ищем продуктивные нетерминалы\n",
        "  new_n_extr= True \n",
        "  while new_n_extr:\n",
        "    new_n_extr = False\n",
        "    for nterm, definition in vars.items():\n",
        "      if nterm not in n_extr and is_non_external(definition):\n",
        "        n_extr.add(nterm)\n",
        "        new_n_extr = True\n",
        "\n",
        "\n",
        "  #ищем достижимые нетерминалы\n",
        "  finded = set(gr['hvar'])\n",
        "  it_grows = True\n",
        "  while it_grows:\n",
        "    it_grows = False\n",
        "    for nterm, definition in vars.items():\n",
        "      if nterm in finded:\n",
        "        for rule in definition:\n",
        "          new_finded = finded.union(set(filter(lambda part: part in vars, rule)))\n",
        "          it_grows = not (len(finded) == len(finded))\n",
        "          finded = new_finded\n",
        "\n",
        "  #получаем множество сторонних нетерминалов\n",
        "  n_extr = n_extr.union(finded)\n",
        "  \n",
        "  #удаляем из грамматики все посторонних нетерминалы и правила в которых они содержатся)\n",
        "  new_vars = dict()\n",
        "  for nterm, definition in vars.items():\n",
        "    if nterm in n_extr:\n",
        "      new_definition = clean_definition(definition)\n",
        "      if nterm not in new_vars.keys() and new_definition:\n",
        "        new_vars[nterm] = []\n",
        "        new_vars[nterm] = new_definition\n",
        "      \n",
        "  gr['vars'] = new_vars\n",
        "\n",
        "  return gr\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIQY4tXrcIrl"
      },
      "source": [
        "To find all vanishing NTs we look through every non-terminal and its product rules and if we find rule like α->ε or α->β, when β->>ε , we are marking this NT as vanishing and repeat while we find new vanishing NTs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGyYlpXHXcNh"
      },
      "source": [
        "def vanishing(gr, empt):\n",
        "  toks = gr['toks']\n",
        "  vars = gr['vars']\n",
        "  vanishing_vars = set() \n",
        "  \n",
        "  #вспомогательная функция для определения исчезаемости нетерминала\n",
        "  def is_vanishing(definition):\n",
        "    for rule in definition: \n",
        "       if all(map((lambda way: way == empt or way in vanishing_vars), rule)): return True\n",
        "    return False\n",
        "\n",
        "  #ищем исчезающие нетерминалы\n",
        "  new_vanishing_flag = True \n",
        "  while new_vanishing_flag:\n",
        "    new_vanishing_flag = False\n",
        "    for nterm, definition in vars.items():\n",
        "      if nterm not in vanishing_vars and is_vanishing(definition) :\n",
        "        vanishing_vars.add(nterm)\n",
        "        new_vanishing_flag = True\n",
        "          \n",
        "  return vanishing_vars.difference(gr['hvar']) #исключаем главный нетерминал\n",
        "\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8uOp-5iXOVV",
        "outputId": "0e4afdd9-957b-489c-9c58-2c6cab475a83"
      },
      "source": [
        "gr = {\n",
        "    'toks': set( [\n",
        "        (0, 'e'), \n",
        "        (1, 'a'), \n",
        "        (2, 'b'), \n",
        "        (3, 'c'),\n",
        "        (4, 'd'),\n",
        "        (5, 'f'),\n",
        "    ] ),\n",
        "\n",
        "    'vars': {\n",
        "        'A' : [['A', (1, 'a')], \n",
        "               ['B', 'F'],\n",
        "               ['C', (3, 'c'), 'D']],\n",
        "        'B' : [['D', (1, 'c')]],\n",
        "        'C' : [['B'],\n",
        "               [(0, 'e')]],\n",
        "        'D' : [['B', (4, 'd')],\n",
        "               ['C', (2, 'b')]],\n",
        "        'F' : [[(0, 'e')],\n",
        "               [(2, 'b'), 'B'],\n",
        "               ['C']],\n",
        "        'S' : [['A']]\n",
        "    },\n",
        "    'hvar': 'S'\n",
        "}\n",
        "\n",
        "print(\"Grammar without unusefull(external) non-terminals: \\n\", clean_external(gr))\n",
        "print(\"Vanishing non-terminals: \", vanishing(gr, (0, 'e')))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar without unusefull(external) non-terminals: \n",
            " {'toks': {(4, 'd'), (5, 'f'), (0, 'e'), (3, 'c'), (2, 'b'), (1, 'a')}, 'vars': {'A': [['A', (1, 'a')], ['C', (3, 'c'), 'D']], 'C': [[(0, 'e')]], 'D': [['C', (2, 'b')]], 'F': [[(0, 'e')], ['C']], 'S': [['A']]}, 'hvar': 'S'}\n",
            "Vanishing non-terminals:  {'F', 'C'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8gxDAaFe73X"
      },
      "source": [
        "Result:\n",
        "Grammar without unusefull(external) non-terminals: {\n",
        "  \n",
        "  'toks': {(2, 'b'), (5, 'f'), (0, 'e'), (4, 'd'), (1, 'a'), (3, 'c')},\n",
        "   \n",
        "   'vars': {'A': [['A', (1, 'a')], ['C', (3, 'c'), 'D']], 'C': [[(0, 'e')]] 'D': [['C', (2, 'b')]], 'F': [[(0, 'e')], ['C']], 'S': [['A']]},\n",
        "   \n",
        "   'hvar': 'S'}\n",
        "   \n",
        "Vanishing non-terminals:  {'F', 'C'}"
      ]
    }
  ]
}